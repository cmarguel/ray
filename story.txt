This logs my attempt to make a raytracer. I have very little idea of how to do this, 
and am more or less making it up as I go along.

23 Sept 2012
	1. 	Implemented basic math and geometry types/functions.
	2. 	Found a page which describes how to get the intersection of a ray and a triangle, so 
	  	that's a huge help right there. http://www.softsurfer.com/Archive/algorithm_0105/algorithm_0105.htm
	3. 	Rendered a simple triangle. Progress?? Right now, the technique is as follows: for each pixel
		in the output, shoot a ray from the camera eye (positioned at width/2,height/2,0) to the 
		corresponding pixel at (x, y, 50). If the ray ever hits a triangle, render it.
	4.	Currently, I'm assuming a very simple camera--stationary, where up is always <0,1,0>.
	5.	Okay, at this point I decided to use PBRT as a reference. At this point I may end up renaming 
		stuff to jive with the book, and adding classes with similar/same names.
		
24 Sept 2012
	1.	Implemented transforms. As per PBRT, we work with 3d vectors, but they're converted to 
		4d vectors during transformations. As far as I know, the fourth dimension is unnecessary
		for rendering, though we should probably keep this to 1.
27 Sept 2012
	1.	Used a simple magnitude comparison to prevent triangles from rendering over triangles in front of them.
	2.	Changed method for computing color, but the way I'm computing color is wrong to begin with, so using the right colors might be the next change. After that, I'll need to work on accelerating rendering by not testing every single triangle.

28 Sept 2012
	1.	Moving Camera into its own folder and implementing LookAt. This camera is a simple pinhole camera.
	2.	On a related note, also moving GenerateRay to camera method, where it should really have been from the start.
	3.	Also, created a World struct for holding world info.

29 Sept 2012
	1.	Added cubes.
	2.	I've temporarily added a color attribute to triangles so that I can color the cubes 
		with Rubik colors to help me figure out what's going on with the perspective.
	3.	Adding lighting, starting with a simple point light. Attenuation is quadratic.
	4.	Will be making the cubes appear in more of a grid-like fashion.
	5.	It seems that my Y-axis is inverted, and I think something might be wrong with the X-axis too.
	
30 Sept 2012
	1.	Started with acceleration structures--primitives and bounding boxes.
	2.	After much effort, finally finished the constructor for GridAccelerator. I think in the future,
		the appropriate way to port a C++/Java style constructor with lots of processing would be to 
		follow a pattern like this: 
		NewFoo() Foo {
			foo := Foo{}
			foo.Initialize()
		}
	3.	At the moment, the grid accelerator will not be supporting multiple threads. Specifically, I
		will leave creating write locks on the grid for later.

7 Oct 2012
	1.  Implemented refine methods and created DifferentialGeometry objects.
	
8 Oct 2012
	2.  Finished grid accelerator, somewhat, but it's creating voxel grids of size 1x1x1, which kind 
		of defeats the purpose. On the other hand, the rendering time has gone down from 15 minutes
		to 6 minutes for rendering 2700 triangles. Gotta look more into this.
21 Oct 2012
	1.	Found a really dumb mistake where I didn't implement a WorldBound method, so the grid 
		accelerator was using just one voxel. Unfortunately, it seems my implementation of the grid 
		accelerator is bugged, because not everything is rendered when I have more than one voxel.
		Debugging tells me that the voxels seem to be populated properly, so I suspect that it's the
		intersection method that's problematic.
		Update: It figures--the one part I hacked up myself was the defective part--I misunderstood
		how computeStepAxis was intended to work, so it was screwing things up majorly. I replaced it
		with a closer approximation of the PBRT code and it worked. From 15 minutes down to 6 seconds.
		Not bad.
23 Oct 2012
	1.	Started on proper lighting, but realized that I need to take a quick detour--at this point it's
		going to get harder to stay in sync with the book if I don't fix my ray struct--direction should
		be a unit vector and relative to <0,0,0>, rather than an absolute coordinate.
	2.	I need to add IntersectP to the Primitive interface and implement it now.
	
12 Nov 2012 
	1.	Next up is to implement sampling. Instead of having one ray correspond to one pixel, I need
		to take several samples per pixel, generate rays for those instead, then weight their 
		contributions to individual pixels with a filter. It should be easy enough to start with a 
		basic box or Gaussian filter.

17 Nov 2012
	1.	It seems I need to make a lot of classes in between if I want things to be less painful 
		moving forward. Working on the Whitted Integrator and Visibility Tester now.
	2.	In PBRT, Lights use VisibilityTesters, VisibilityTesters use Scenes, and Scenes use Lights.
		The way I've organized things here, I had to put visibilityTester.Unoccluded in world 
		instead. This might be incorrect design-wise, so I may have to rethink how the packages are 
		structured.
		
11 Dec 2012
	1.	I've been unable to think of a way to correct the visibility tester compromise I made, so
		now I am going to be working on splitting the rendering up into tasks that may be run in 
		parallel. I may not have to ape too much from PBRT for this, since goroutines are fairly 
		different from threads. I'm thinking that the appropriate thing to do is to create a fixed
		number of goroutines which I pass tasks to.

13 Dec 2012
	1.	Something's weird--when I add a test that a point is unoccluded, several seemingly random
		pixels fail to render. Either something is wrong with one of the IntersectP methods, or the
		rays that SampleL is setting are incorrect (possibly going in the reverse direction 
		they're supposed to?).
		-- Okay, I tested the latter guess by reversing the direction of the rays in the 
		visibilityTester. It seems my guess is incorrect, because the missing pixels don't render, 
		but the occluded sides do render (with the same bug). My new suspicion is that the points
		intersect with themselves.
		-- Fixed. PBRT confirmed my guess. I was not using RayEpsilon, which was meant to solve
		this exact problem.
		
14 Dec 2012
	1. 	I think I need to distribute the rendering across multiple tasks now before I can start
		on sampling.
		-- Added rudimentary task distribution, no sampling.
		
16 Dec 2012
	1.	I'm working on the ImageFilm class. Currently, instead of adding samples, I'm just adding
		straight up values (although I've already put placeholders for weights).

18 Dec 2012
	1.	Finally making renderer use samples (albeit still using a uniform strategy). This required
		some code to be moved around a little.
	2.	And now I added a Gaussian filter, which should hopefully help antialias once I start 
		taking multiple samples. In PBRT, the film precomputes a weight table for its filters,
		and just approximates the real value. For now, I'll try using the exact value, and if
		it works out, I'll precompute the table and see how much faster it gets.

24 Dec 2012
	1.	Implemented stratified sampling. Image looks quite good now; however, tracing is much much
		slower. I'll probably need to do the precomputed filter values now to make it fast again.
		I haven't implemented Latin Hypercube sampling, which may be important down the line.
	2.	I also added a precomputed table, but I took it out for now as it is either incorrect, or
		not currently useful--the image looks significantly worse with a precomputed table of filter
		values. This shouldn't be the case, but I haven't found where it could have gone wrong.
		-- Found the error, and it was entirely my fault. I had an i where I should have put a y.
		Unfortunately, the speed gain doesn't seem to be much, so I'll need to look into other 
		optimizations.

27-28 Dec 2012
	1.	Created parser for PBRT format. That was a lot of work, but it's pretty boring and I don't 
		feel that it's productive to document the parser too thoroughly. My main problem seems to be
		displaying things--all I get are tiny illuminated polygons. 